{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7857c46e-bfcf-4109-84cb-984073104970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da5f78ee-b333-4bf2-8c08-fefe0beb7b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>official_name</th>\n",
       "      <th>cite_key</th>\n",
       "      <th>folder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NoveltySVR</td>\n",
       "      <td>~\\cite{ma2003online}</td>\n",
       "      <td>novelty_svr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PS-SVM</td>\n",
       "      <td>~\\cite{ma2003time}</td>\n",
       "      <td>phasespace_svm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EmsembleGI</td>\n",
       "      <td>~\\cite{gao2020ensemble}</td>\n",
       "      <td>ensemble_gi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GrammarViz</td>\n",
       "      <td>~\\cite{senin2015time}</td>\n",
       "      <td>grammarviz3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOT SAX</td>\n",
       "      <td>~\\cite{keogh2005hot}</td>\n",
       "      <td>hotsax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TSBitmap</td>\n",
       "      <td>~\\cite{wei2005assumption}</td>\n",
       "      <td>ts_bitmap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NormA-SJ</td>\n",
       "      <td>~\\cite{boniol2021unsupervised}</td>\n",
       "      <td>norma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SAND</td>\n",
       "      <td>~\\cite{boniol2021sand}</td>\n",
       "      <td>sand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Series2Graph</td>\n",
       "      <td>~\\cite{boniol2022series2graph}</td>\n",
       "      <td>series2graph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>STAMP</td>\n",
       "      <td>~\\cite{yeh2016matrix}</td>\n",
       "      <td>stamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>STOMP</td>\n",
       "      <td>~\\cite{zhu2016matrix}</td>\n",
       "      <td>stomp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>VALMOD</td>\n",
       "      <td>~\\cite{linardi2020matrix}</td>\n",
       "      <td>valmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Left STAMPi</td>\n",
       "      <td>~\\cite{yeh2016matrix}</td>\n",
       "      <td>left_stampi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SSA</td>\n",
       "      <td>~\\cite{yao2010online}</td>\n",
       "      <td>ssa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PST</td>\n",
       "      <td>~\\cite{sun2006mining}</td>\n",
       "      <td>pst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NumetaHTM</td>\n",
       "      <td>~\\cite{ahmad2017unsupervised}</td>\n",
       "      <td>numenta_htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sub-LOF</td>\n",
       "      <td>~\\cite{breunig2000lof}</td>\n",
       "      <td>subsequence_lof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sub-IF</td>\n",
       "      <td>~\\cite{liu2008isolation}</td>\n",
       "      <td>subsequence_if</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DWT-MLEAD</td>\n",
       "      <td>~\\cite{thill2017time}</td>\n",
       "      <td>dwt_mlead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>FFT</td>\n",
       "      <td>~\\cite{rasheed2009fourier}</td>\n",
       "      <td>fft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SR</td>\n",
       "      <td>~\\cite{ren2019time}</td>\n",
       "      <td>sr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>S-H-ESD</td>\n",
       "      <td>~\\cite{hochenbaum2017automatic}</td>\n",
       "      <td>s_h_esd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DSPOT</td>\n",
       "      <td>~\\cite{siffer2017anomaly}</td>\n",
       "      <td>dspot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ARIMA</td>\n",
       "      <td>~\\cite{hyndman2018forecasting}</td>\n",
       "      <td>arima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MedianMethod</td>\n",
       "      <td>~\\cite{basu2007automatic}</td>\n",
       "      <td>median_method</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SARIMA</td>\n",
       "      <td>~\\cite{greis2018comparing}</td>\n",
       "      <td>sarima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Triple ES</td>\n",
       "      <td>~\\cite{aboode2018anomaly}</td>\n",
       "      <td>triple_es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>PCI</td>\n",
       "      <td>~\\cite{yu2014time}</td>\n",
       "      <td>pci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RForest</td>\n",
       "      <td>~\\cite{breiman2001random}</td>\n",
       "      <td>generic_rf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>XGBoosting</td>\n",
       "      <td>~\\cite{chen2016xgboost}</td>\n",
       "      <td>generic_xgb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>TARZAN</td>\n",
       "      <td>~\\cite{keogh2002finding}</td>\n",
       "      <td>tarzan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>HealthESN</td>\n",
       "      <td>~\\cite{chen2020imbalanced}</td>\n",
       "      <td>health_esn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>OceanWNN</td>\n",
       "      <td>~\\cite{wang2019study}</td>\n",
       "      <td>ocean_wnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Bagel</td>\n",
       "      <td>~\\cite{li2018robust}</td>\n",
       "      <td>bagel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Donut</td>\n",
       "      <td>~\\cite{xu2018unsupervised}</td>\n",
       "      <td>donut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>IE-CAE</td>\n",
       "      <td>~\\cite{garcia2020time}</td>\n",
       "      <td>img_embedding_cae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>SR-CNN</td>\n",
       "      <td>~\\cite{ren2019time}</td>\n",
       "      <td>sr_cnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Sub-Fast-MCD</td>\n",
       "      <td>~\\cite{rousseeuw1999fast}</td>\n",
       "      <td>subsequence_fast_mcd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SNPAD</td>\n",
       "      <td>~\\cite{zhou2023semi}</td>\n",
       "      <td>snpad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>COUTA</td>\n",
       "      <td>~\\cite{xu2022calibrated}</td>\n",
       "      <td>couta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   official_name                         cite_key                folder\n",
       "0     NoveltySVR             ~\\cite{ma2003online}           novelty_svr\n",
       "1         PS-SVM               ~\\cite{ma2003time}        phasespace_svm\n",
       "2     EmsembleGI          ~\\cite{gao2020ensemble}           ensemble_gi\n",
       "3     GrammarViz            ~\\cite{senin2015time}           grammarviz3\n",
       "4        HOT SAX             ~\\cite{keogh2005hot}                hotsax\n",
       "5       TSBitmap        ~\\cite{wei2005assumption}             ts_bitmap\n",
       "6       NormA-SJ   ~\\cite{boniol2021unsupervised}                 norma\n",
       "7           SAND           ~\\cite{boniol2021sand}                  sand\n",
       "8   Series2Graph   ~\\cite{boniol2022series2graph}          series2graph\n",
       "9          STAMP            ~\\cite{yeh2016matrix}                 stamp\n",
       "10         STOMP            ~\\cite{zhu2016matrix}                 stomp\n",
       "11        VALMOD        ~\\cite{linardi2020matrix}                valmod\n",
       "12   Left STAMPi            ~\\cite{yeh2016matrix}           left_stampi\n",
       "13           SSA            ~\\cite{yao2010online}                   ssa\n",
       "14           PST            ~\\cite{sun2006mining}                   pst\n",
       "15     NumetaHTM    ~\\cite{ahmad2017unsupervised}           numenta_htm\n",
       "16       Sub-LOF           ~\\cite{breunig2000lof}       subsequence_lof\n",
       "17        Sub-IF         ~\\cite{liu2008isolation}        subsequence_if\n",
       "18     DWT-MLEAD            ~\\cite{thill2017time}             dwt_mlead\n",
       "19           FFT       ~\\cite{rasheed2009fourier}                   fft\n",
       "20            SR              ~\\cite{ren2019time}                    sr\n",
       "21       S-H-ESD  ~\\cite{hochenbaum2017automatic}               s_h_esd\n",
       "22         DSPOT        ~\\cite{siffer2017anomaly}                 dspot\n",
       "23         ARIMA   ~\\cite{hyndman2018forecasting}                 arima\n",
       "24  MedianMethod        ~\\cite{basu2007automatic}         median_method\n",
       "25        SARIMA       ~\\cite{greis2018comparing}                sarima\n",
       "26     Triple ES        ~\\cite{aboode2018anomaly}             triple_es\n",
       "27           PCI               ~\\cite{yu2014time}                   pci\n",
       "28       RForest        ~\\cite{breiman2001random}            generic_rf\n",
       "29    XGBoosting          ~\\cite{chen2016xgboost}           generic_xgb\n",
       "30        TARZAN         ~\\cite{keogh2002finding}                tarzan\n",
       "31     HealthESN       ~\\cite{chen2020imbalanced}            health_esn\n",
       "32      OceanWNN            ~\\cite{wang2019study}             ocean_wnn\n",
       "33         Bagel             ~\\cite{li2018robust}                 bagel\n",
       "34         Donut       ~\\cite{xu2018unsupervised}                 donut\n",
       "35        IE-CAE           ~\\cite{garcia2020time}     img_embedding_cae\n",
       "36        SR-CNN              ~\\cite{ren2019time}                sr_cnn\n",
       "37  Sub-Fast-MCD        ~\\cite{rousseeuw1999fast}  subsequence_fast_mcd\n",
       "38         SNPAD            ~\\cite{zhou2023semi}                  snpad\n",
       "39         COUTA         ~\\cite{xu2022calibrated}                 couta"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "mapping_alg = pd.read_csv(\"algorithm_mapping.csv\")\n",
    "mapping_alg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "153b8c53-0e87-4c6d-bcbc-52afc577693c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_long_shutdown(numbers, num_consecutive, missing_label):\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "\n",
    "    i = 0\n",
    "    while i < len(numbers)-1:\n",
    "        num = numbers[i]\n",
    "        if num != missing_label:\n",
    "            current_chunk.append(i)\n",
    "        else:\n",
    "            j = i+1\n",
    "            while j < len(numbers):\n",
    "                if numbers[j] == missing_label:\n",
    "                    j += 1\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            if j-i < num_consecutive:\n",
    "                current_chunk += range(i,min(j+1, len(numbers)))# numbers[i:j+1]\n",
    "            else:\n",
    "                chunks.append(current_chunk)\n",
    "                current_chunk = []\n",
    "\n",
    "            i=j         \n",
    "\n",
    "        i+= 1\n",
    "\n",
    "    # Append the last chunk\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk)\n",
    "\n",
    "    to_ret = []\n",
    "    # Print the chunks\n",
    "    for i, chunk in enumerate(chunks, 1):\n",
    "        to_ret += chunk\n",
    "        \n",
    "    return to_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a94a91d7-0611-4b6a-aa69-3048f66e8d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csc_matrix, hstack\n",
    "import numpy as np\n",
    "# code taken from https://github.com/HPI-Information-Systems/TimeEval-algorithms\n",
    "def post_grammarviz(algorithm_parameter):\n",
    "    if isinstance(algorithm_parameter, np.ndarray):\n",
    "        results = pd.DataFrame(algorithm_parameter, columns=[\"index\", \"score\", \"length\"])\n",
    "        results = results.set_index(\"index\")\n",
    "    else:\n",
    "        results = pd.read_csv(algorithm_parameter, header=None, index_col=0, names=[\"index\", \"score\", \"length\"])\n",
    "    anomalies = results[results[\"score\"] > .0]\n",
    "\n",
    "    # use scipy sparse matrix to save memory\n",
    "    matrix = csc_matrix((len(results), 1), dtype=np.float64)\n",
    "    counts = np.zeros(len(results))\n",
    "    for i, row in anomalies.iterrows():\n",
    "        idx = int(row.name)\n",
    "        length = int(row[\"length\"])\n",
    "        tmp = np.zeros(len(results))\n",
    "        tmp[idx:idx + length] = np.repeat([row[\"score\"]], repeats=length)\n",
    "        tmp = tmp.reshape(-1, 1)\n",
    "        matrix = hstack([matrix, tmp])\n",
    "        counts[idx:idx + length] += 1\n",
    "    sums = matrix.sum(axis=1)\n",
    "    counts = counts.reshape(-1, 1)\n",
    "    scores = np.zeros_like(sums)\n",
    "    np.divide(sums, counts, out=scores, where=counts != 0)\n",
    "    # returns the completely flattened array (from `[[1.2], [2.3]]` to `[1.2, 2.3]`)\n",
    "    return scores.A1  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf6fbe7d-8aa4-4330-9927-a338eb2f3bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "import traceback\n",
    "import math\n",
    "from scipy.sparse import csc_matrix, hstack\n",
    "\n",
    "# code taken from https://github.com/HPI-Information-Systems/TimeEval-algorithms\n",
    "def post_grammarviz(algorithm_parameter):\n",
    "    if isinstance(algorithm_parameter, np.ndarray):\n",
    "        results = pd.DataFrame(algorithm_parameter, columns=[\"index\", \"score\", \"length\"])\n",
    "        results = results.set_index(\"index\")\n",
    "    else:\n",
    "        results = pd.read_csv(algorithm_parameter, header=None, index_col=0, names=[\"index\", \"score\", \"length\"])\n",
    "    anomalies = results[results[\"score\"] > .0]\n",
    "\n",
    "    # use scipy sparse matrix to save memory\n",
    "    matrix = csc_matrix((len(results), 1), dtype=np.float64)\n",
    "    counts = np.zeros(len(results))\n",
    "    for i, row in anomalies.iterrows():\n",
    "        idx = int(row.name)\n",
    "        length = int(row[\"length\"])\n",
    "        tmp = np.zeros(len(results))\n",
    "        tmp[idx:idx + length] = np.repeat([row[\"score\"]], repeats=length)\n",
    "        tmp = tmp.reshape(-1, 1)\n",
    "        matrix = hstack([matrix, tmp])\n",
    "        counts[idx:idx + length] += 1\n",
    "    sums = matrix.sum(axis=1)\n",
    "    counts = counts.reshape(-1, 1)\n",
    "    scores = np.zeros_like(sums)\n",
    "    np.divide(sums, counts, out=scores, where=counts != 0)\n",
    "    # returns the completely flattened array (from `[[1.2], [2.3]]` to `[1.2, 2.3]`)\n",
    "    return scores.A1  # type: ignore\n",
    "\n",
    "def calculate_roc(path_to_result, label_file, data_source, feasibility=None, validation=None):\n",
    "    try:\n",
    "        roc_scores = dict()\n",
    "        roc_scores_file = dict()\n",
    "        pr_scores = dict()\n",
    "        pr_scores_file = dict()\n",
    "        \n",
    "        i = 0\n",
    "        for result_file in os.listdir(path_to_result):\n",
    "            print(f\"{i}/{len(os.listdir(path_to_result))}: {result_file}                   \", end=\"\\r\")\n",
    "            i += 1\n",
    "            \n",
    "            if data_source in result_file and result_file.endswith(\".ts\"):\n",
    "                alg_name = result_file[:result_file.find(data_source)]\n",
    "                alg_name = '_'.join(alg_name.split('_')[1:])[:-1]\n",
    "                try:\n",
    "                    official_name = mapping_alg[mapping_alg.folder == alg_name].official_name.values[0]\n",
    "                    roc_auc, pr_auc = 0, 0\n",
    "                    \n",
    "                    if official_name == \"GrammarViz\":\n",
    "                        result_alg = post_grammarviz(path_to_result + result_file)\n",
    "                    else:\n",
    "                        result_alg = np.loadtxt(path_to_result + result_file)\n",
    "                        \n",
    "                    result_alg = pd.DataFrame(result_alg, columns=[\"alg_anomaly_score\"])\n",
    "                    result_alg[\"alg_anomaly_score\"] = result_alg[\"alg_anomaly_score\"].astype(float)\n",
    "                    result_alg = result_alg.fillna(0)\n",
    "                    result_alg.replace(np.inf, 1, inplace=True)\n",
    "                    result_alg.replace(-np.inf, 1, inplace=True)\n",
    "\n",
    "                    label = pd.read_csv(label_file)\n",
    "                    label = label[-len(result_alg):]\n",
    "                    label = label.reset_index(drop=True)\n",
    "\n",
    "                    if feasibility:\n",
    "                        label_feasibility = pd.read_csv(feasibility)\n",
    "\n",
    "                    total = pd.concat([result_alg, label], axis=1, join='inner')\n",
    "                    if feasibility:\n",
    "                        total = total[:len(total)-len(label_feasibility)]\n",
    "\n",
    "                    total = total.reset_index(drop=True)\n",
    "                    total = pd.concat([result_alg, label], axis=1, join='inner')\n",
    "                    observed_values = total.value.values.tolist()\n",
    "                    observed_values = [int(x) for x in observed_values]\n",
    "                    to_keep_comparision = remove_long_shutdown(observed_values, THRESHOLD_INDICATING_SHUTDOWN, MISSING_VALUE)\n",
    "                    total=total[total.index.isin(to_keep_comparision)]\n",
    "                    \n",
    "                    try:\n",
    "                        roc_auc = metrics.roc_auc_score(total.is_anomaly, total.alg_anomaly_score)\n",
    "                    except:\n",
    "                        roc_auc = 0\n",
    "\n",
    "                    try:\n",
    "                        y, x, _ = metrics.precision_recall_curve(total.is_anomaly, total.alg_anomaly_score)\n",
    "                        pr_auc = metrics.auc(x, y)\n",
    "                    except:\n",
    "                        pr_auc = 0\n",
    "                    \n",
    "                    if official_name not in roc_scores.keys():\n",
    "                        roc_scores[official_name] = roc_auc\n",
    "                        pr_scores[official_name] = pr_auc\n",
    "                        roc_scores_file[official_name] = pr_scores_file[official_name] = result_file\n",
    "                    else:\n",
    "                        if roc_auc > roc_scores[official_name]:\n",
    "                            roc_scores[official_name] = roc_auc\n",
    "                            roc_scores_file[official_name] = result_file\n",
    "                        if pr_auc > pr_scores[official_name]:\n",
    "                            pr_scores[official_name] = pr_auc\n",
    "                            pr_scores_file[official_name] = result_file\n",
    "                        \n",
    "                except:\n",
    "                    #traceback.print_exc()\n",
    "                    try:\n",
    "                        if official_name not in roc_scores.keys():\n",
    "                            roc_scores[official_name] = max(0, roc_auc)\n",
    "                            pr_scores[official_name] = max(0, pr_auc)\n",
    "                        else:\n",
    "                            if roc_auc > roc_scores[official_name]:\n",
    "                                roc_scores[official_name] = max(0, roc_auc)\n",
    "                            if pr_auc > pr_scores[official_name]:\n",
    "                                pr_scores[official_name] =max(0, pr_auc)\n",
    "                    except:\n",
    "                        pass\n",
    "        \n",
    "        return roc_scores, pr_scores\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4328498-a591-4659-9657-67691c7ef1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197/198: adapad_subsequence_fast_mcd_Tide_Pressure_increased_00000.ts                   \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'Bagel': 0.7407473406139005,\n",
       "  'Donut': 0.7911282125190542,\n",
       "  'RForest': 0.8066295907280518,\n",
       "  'XGBoosting': 0.8085833485283902,\n",
       "  'HealthESN': 0.7704684949961799,\n",
       "  'IE-CAE': 0.414203434936776,\n",
       "  'OceanWNN': 0.772076031543431,\n",
       "  'SR-CNN': 0.3793695834645634,\n",
       "  'Sub-Fast-MCD': 0.8283779156972777},\n",
       " {'Bagel': 0.4793123512255489,\n",
       "  'Donut': 0.5735143263891832,\n",
       "  'RForest': 0.6131089646048136,\n",
       "  'XGBoosting': 0.6132794167545834,\n",
       "  'HealthESN': 0.15188696643360797,\n",
       "  'IE-CAE': 0.005316275183668032,\n",
       "  'OceanWNN': 0.6144810954957423,\n",
       "  'SR-CNN': 0.021933582116022192,\n",
       "  'Sub-Fast-MCD': 0.059507383203809994})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THRESHOLD_INDICATING_SHUTDOWN = 30\n",
    "MISSING_VALUE = -999\n",
    "OPERATION_VAL_RANGE = (713.682, 763.826)\n",
    "\n",
    "path_to_result = \"./experiments/\"\n",
    "label_file = \"../../01_data/01_label/Tide_pressure.csv\"\n",
    "feasibility = \"../../01_data/01_label/Tide_pressure.bechmark_stage.csv\"\n",
    "validation = None\n",
    "data_source = \"Tide_Pressure\"\n",
    "calculate_roc(path_to_result, label_file, data_source, feasibility,validation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
