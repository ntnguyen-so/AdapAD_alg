{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7857c46e-bfcf-4109-84cb-984073104970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da5f78ee-b333-4bf2-8c08-fefe0beb7b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>official_name</th>\n",
       "      <th>cite_key</th>\n",
       "      <th>folder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NoveltySVR</td>\n",
       "      <td>~\\cite{ma2003online}</td>\n",
       "      <td>novelty_svr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PS-SVM</td>\n",
       "      <td>~\\cite{ma2003time}</td>\n",
       "      <td>phasespace_svm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EmsembleGI</td>\n",
       "      <td>~\\cite{gao2020ensemble}</td>\n",
       "      <td>ensemble_gi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GrammarViz</td>\n",
       "      <td>~\\cite{senin2015time}</td>\n",
       "      <td>grammarviz3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOT SAX</td>\n",
       "      <td>~\\cite{keogh2005hot}</td>\n",
       "      <td>hotsax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TSBitmap</td>\n",
       "      <td>~\\cite{wei2005assumption}</td>\n",
       "      <td>ts_bitmap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NormA-SJ</td>\n",
       "      <td>~\\cite{boniol2021unsupervised}</td>\n",
       "      <td>norma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SAND</td>\n",
       "      <td>~\\cite{boniol2021sand}</td>\n",
       "      <td>sand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Series2Graph</td>\n",
       "      <td>~\\cite{boniol2022series2graph}</td>\n",
       "      <td>series2graph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>STAMP</td>\n",
       "      <td>~\\cite{yeh2016matrix}</td>\n",
       "      <td>stamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>STOMP</td>\n",
       "      <td>~\\cite{zhu2016matrix}</td>\n",
       "      <td>stomp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>VALMOD</td>\n",
       "      <td>~\\cite{linardi2020matrix}</td>\n",
       "      <td>valmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Left STAMPi</td>\n",
       "      <td>~\\cite{yeh2016matrix}</td>\n",
       "      <td>left_stampi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SSA</td>\n",
       "      <td>~\\cite{yao2010online}</td>\n",
       "      <td>ssa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PST</td>\n",
       "      <td>~\\cite{sun2006mining}</td>\n",
       "      <td>pst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NumetaHTM</td>\n",
       "      <td>~\\cite{ahmad2017unsupervised}</td>\n",
       "      <td>numenta_htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sub-LOF</td>\n",
       "      <td>~\\cite{breunig2000lof}</td>\n",
       "      <td>subsequence_lof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sub-IF</td>\n",
       "      <td>~\\cite{liu2008isolation}</td>\n",
       "      <td>subsequence_if</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DWT-MLEAD</td>\n",
       "      <td>~\\cite{thill2017time}</td>\n",
       "      <td>dwt_mlead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>FFT</td>\n",
       "      <td>~\\cite{rasheed2009fourier}</td>\n",
       "      <td>fft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SR</td>\n",
       "      <td>~\\cite{ren2019time}</td>\n",
       "      <td>sr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>S-H-ESD</td>\n",
       "      <td>~\\cite{hochenbaum2017automatic}</td>\n",
       "      <td>s_h_esd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DSPOT</td>\n",
       "      <td>~\\cite{siffer2017anomaly}</td>\n",
       "      <td>dspot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ARIMA</td>\n",
       "      <td>~\\cite{hyndman2018forecasting}</td>\n",
       "      <td>arima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MedianMethod</td>\n",
       "      <td>~\\cite{basu2007automatic}</td>\n",
       "      <td>median_method</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SARIMA</td>\n",
       "      <td>~\\cite{greis2018comparing}</td>\n",
       "      <td>sarima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Triple ES</td>\n",
       "      <td>~\\cite{aboode2018anomaly}</td>\n",
       "      <td>triple_es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>PCI</td>\n",
       "      <td>~\\cite{yu2014time}</td>\n",
       "      <td>pci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RForest</td>\n",
       "      <td>~\\cite{breiman2001random}</td>\n",
       "      <td>generic_rf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>XGBoosting</td>\n",
       "      <td>~\\cite{chen2016xgboost}</td>\n",
       "      <td>generic_xgb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>TARZAN</td>\n",
       "      <td>~\\cite{keogh2002finding}</td>\n",
       "      <td>tarzan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>HealthESN</td>\n",
       "      <td>~\\cite{chen2020imbalanced}</td>\n",
       "      <td>health_esn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>OceanWNN</td>\n",
       "      <td>~\\cite{wang2019study}</td>\n",
       "      <td>ocean_wnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Bagel</td>\n",
       "      <td>~\\cite{li2018robust}</td>\n",
       "      <td>bagel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Donut</td>\n",
       "      <td>~\\cite{xu2018unsupervised}</td>\n",
       "      <td>donut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>IE-CAE</td>\n",
       "      <td>~\\cite{garcia2020time}</td>\n",
       "      <td>img_embedding_cae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>SR-CNN</td>\n",
       "      <td>~\\cite{ren2019time}</td>\n",
       "      <td>sr_cnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Sub-Fast-MCD</td>\n",
       "      <td>~\\cite{rousseeuw1999fast}</td>\n",
       "      <td>subsequence_fast_mcd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SNPAD</td>\n",
       "      <td>~\\cite{zhou2023semi}</td>\n",
       "      <td>snpad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>COUTA</td>\n",
       "      <td>~\\cite{xu2022calibrated}</td>\n",
       "      <td>couta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   official_name                         cite_key                folder\n",
       "0     NoveltySVR             ~\\cite{ma2003online}           novelty_svr\n",
       "1         PS-SVM               ~\\cite{ma2003time}        phasespace_svm\n",
       "2     EmsembleGI          ~\\cite{gao2020ensemble}           ensemble_gi\n",
       "3     GrammarViz            ~\\cite{senin2015time}           grammarviz3\n",
       "4        HOT SAX             ~\\cite{keogh2005hot}                hotsax\n",
       "5       TSBitmap        ~\\cite{wei2005assumption}             ts_bitmap\n",
       "6       NormA-SJ   ~\\cite{boniol2021unsupervised}                 norma\n",
       "7           SAND           ~\\cite{boniol2021sand}                  sand\n",
       "8   Series2Graph   ~\\cite{boniol2022series2graph}          series2graph\n",
       "9          STAMP            ~\\cite{yeh2016matrix}                 stamp\n",
       "10         STOMP            ~\\cite{zhu2016matrix}                 stomp\n",
       "11        VALMOD        ~\\cite{linardi2020matrix}                valmod\n",
       "12   Left STAMPi            ~\\cite{yeh2016matrix}           left_stampi\n",
       "13           SSA            ~\\cite{yao2010online}                   ssa\n",
       "14           PST            ~\\cite{sun2006mining}                   pst\n",
       "15     NumetaHTM    ~\\cite{ahmad2017unsupervised}           numenta_htm\n",
       "16       Sub-LOF           ~\\cite{breunig2000lof}       subsequence_lof\n",
       "17        Sub-IF         ~\\cite{liu2008isolation}        subsequence_if\n",
       "18     DWT-MLEAD            ~\\cite{thill2017time}             dwt_mlead\n",
       "19           FFT       ~\\cite{rasheed2009fourier}                   fft\n",
       "20            SR              ~\\cite{ren2019time}                    sr\n",
       "21       S-H-ESD  ~\\cite{hochenbaum2017automatic}               s_h_esd\n",
       "22         DSPOT        ~\\cite{siffer2017anomaly}                 dspot\n",
       "23         ARIMA   ~\\cite{hyndman2018forecasting}                 arima\n",
       "24  MedianMethod        ~\\cite{basu2007automatic}         median_method\n",
       "25        SARIMA       ~\\cite{greis2018comparing}                sarima\n",
       "26     Triple ES        ~\\cite{aboode2018anomaly}             triple_es\n",
       "27           PCI               ~\\cite{yu2014time}                   pci\n",
       "28       RForest        ~\\cite{breiman2001random}            generic_rf\n",
       "29    XGBoosting          ~\\cite{chen2016xgboost}           generic_xgb\n",
       "30        TARZAN         ~\\cite{keogh2002finding}                tarzan\n",
       "31     HealthESN       ~\\cite{chen2020imbalanced}            health_esn\n",
       "32      OceanWNN            ~\\cite{wang2019study}             ocean_wnn\n",
       "33         Bagel             ~\\cite{li2018robust}                 bagel\n",
       "34         Donut       ~\\cite{xu2018unsupervised}                 donut\n",
       "35        IE-CAE           ~\\cite{garcia2020time}     img_embedding_cae\n",
       "36        SR-CNN              ~\\cite{ren2019time}                sr_cnn\n",
       "37  Sub-Fast-MCD        ~\\cite{rousseeuw1999fast}  subsequence_fast_mcd\n",
       "38         SNPAD            ~\\cite{zhou2023semi}                  snpad\n",
       "39         COUTA         ~\\cite{xu2022calibrated}                 couta"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "mapping_alg = pd.read_csv(\"algorithm_mapping.csv\")\n",
    "mapping_alg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "153b8c53-0e87-4c6d-bcbc-52afc577693c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is to remove periods when the sensor is considered turned off.\n",
    "# This can happen, for example, when the sensor is out-of-battery or turned off by humans to avoid polluted water (see Section 2.2.2).\n",
    "# As agreed with all of our domain experts, such periods should not be measured in terms of precision.\n",
    "\n",
    "def remove_long_shutdown(numbers, num_consecutive, missing_label):\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "\n",
    "    i = 0\n",
    "    while i < len(numbers)-1:\n",
    "        num = numbers[i]\n",
    "        if num != missing_label:\n",
    "            current_chunk.append(i)\n",
    "        else:\n",
    "            j = i+1\n",
    "            while j < len(numbers):\n",
    "                if numbers[j] == missing_label:\n",
    "                    j += 1\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            if j-i < num_consecutive:\n",
    "                current_chunk += range(i,min(j+1, len(numbers)))# numbers[i:j+1]\n",
    "            else:\n",
    "                chunks.append(current_chunk)\n",
    "                current_chunk = []\n",
    "\n",
    "            i=j         \n",
    "\n",
    "        i+= 1\n",
    "\n",
    "    # Append the last chunk\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk)\n",
    "\n",
    "    to_ret = []\n",
    "    # Print the chunks\n",
    "    for i, chunk in enumerate(chunks, 1):\n",
    "        to_ret += chunk\n",
    "        \n",
    "    return to_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a94a91d7-0611-4b6a-aa69-3048f66e8d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csc_matrix, hstack\n",
    "import numpy as np\n",
    "# code taken from https://github.com/HPI-Information-Systems/TimeEval-algorithms\n",
    "def post_grammarviz(algorithm_parameter):\n",
    "    if isinstance(algorithm_parameter, np.ndarray):\n",
    "        results = pd.DataFrame(algorithm_parameter, columns=[\"index\", \"score\", \"length\"])\n",
    "        results = results.set_index(\"index\")\n",
    "    else:\n",
    "        results = pd.read_csv(algorithm_parameter, header=None, index_col=0, names=[\"index\", \"score\", \"length\"])\n",
    "    anomalies = results[results[\"score\"] > .0]\n",
    "\n",
    "    # use scipy sparse matrix to save memory\n",
    "    matrix = csc_matrix((len(results), 1), dtype=np.float64)\n",
    "    counts = np.zeros(len(results))\n",
    "    for i, row in anomalies.iterrows():\n",
    "        idx = int(row.name)\n",
    "        length = int(row[\"length\"])\n",
    "        tmp = np.zeros(len(results))\n",
    "        tmp[idx:idx + length] = np.repeat([row[\"score\"]], repeats=length)\n",
    "        tmp = tmp.reshape(-1, 1)\n",
    "        matrix = hstack([matrix, tmp])\n",
    "        counts[idx:idx + length] += 1\n",
    "    sums = matrix.sum(axis=1)\n",
    "    counts = counts.reshape(-1, 1)\n",
    "    scores = np.zeros_like(sums)\n",
    "    np.divide(sums, counts, out=scores, where=counts != 0)\n",
    "    # returns the completely flattened array (from `[[1.2], [2.3]]` to `[1.2, 2.3]`)\n",
    "    return scores.A1  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f30fa3f3-2730-49e3-8a75-4a75d0bde628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "import traceback\n",
    "from collections import defaultdict\n",
    "\n",
    "# code taken from https://arxiv.org/abs/2207.12201 (COUTA algorithm)\n",
    "def get_best_f1(label, score):\n",
    "    precision, recall, ths = metrics.precision_recall_curve(y_true=label, probas_pred=score)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-5)\n",
    "    best_f1 = f1[np.argmax(f1)]\n",
    "    best_p = precision[np.argmax(f1)]\n",
    "    best_r = recall[np.argmax(f1)]\n",
    "    best_th = ths[np.argmax(f1)]\n",
    "    return best_f1, best_th\n",
    "\n",
    "def calculate_f1(path_to_result, label_file, data_source, feasibility=None, validation=None):\n",
    "    try:\n",
    "        f1_scores = dict()\n",
    "        f1_scores_file = dict()\n",
    "        f1_scores_th = dict()\n",
    "        \n",
    "        i = 0\n",
    "        for result_file in os.listdir(path_to_result):\n",
    "            print(f\"{i}/{len(os.listdir(path_to_result))}: {result_file}                   \", end=\"\\r\")\n",
    "            i += 1\n",
    "            \n",
    "            if data_source in result_file and result_file.endswith(\".ts\"):\n",
    "                alg_name = result_file[:result_file.find(data_source)]\n",
    "                alg_name = '_'.join(alg_name.split('_')[1:])[:-1]                        \n",
    "                try:\n",
    "                    official_name = mapping_alg[mapping_alg.folder == alg_name].official_name.values[0]\n",
    "                    f  = 0\n",
    "                    \n",
    "                    if official_name == \"GrammarViz\":\n",
    "                        result_alg = post_grammarviz(path_to_result+result_file)\n",
    "                    else:\n",
    "                        result_alg = np.loadtxt(path_to_result+result_file)\n",
    "                    result_alg = pd.DataFrame(result_alg, columns=[\"alg_anomaly_score\"])\n",
    "                        \n",
    "                    result_alg[\"alg_anomaly_score\"] = result_alg[\"alg_anomaly_score\"].astype(float)\n",
    "                    result_alg = result_alg.fillna(0)\n",
    "                    result_alg.replace(np.inf, 1, inplace=True)\n",
    "                    result_alg.replace(-np.inf, 1, inplace=True)\n",
    "                    #result_alg = result_alg.reset_index(drop=True)\n",
    "\n",
    "                    label = pd.read_csv(label_file)\n",
    "                    label = label[-len(result_alg):]\n",
    "                    label = label.reset_index(drop=True)\n",
    "\n",
    "                    if feasibility:\n",
    "                        label_feasibility = pd.read_csv(feasibility)\n",
    "                    elif validation:\n",
    "                        label_validation = pd.read_csv(validation)\n",
    "\n",
    "                    total = pd.concat([result_alg, label], axis=1, join='inner')\n",
    "                    if feasibility:\n",
    "                        total = total[:len(total)-len(label_feasibility)]\n",
    "                    elif validation:\n",
    "                        total = total[-len(label_validation):]\n",
    "                    \n",
    "                    total = total.reset_index(drop=True)\n",
    "                    observed_values = total.value.values.tolist()\n",
    "                    observed_values = [int(x) for x in observed_values]\n",
    "                    to_keep_comparision = remove_long_shutdown(observed_values, THRESHOLD_INDICATING_SHUTDOWN, MISSING_VALUE)\n",
    "                    total=total[total.index.isin(to_keep_comparision)]\n",
    "                    \n",
    "                    f, th = get_best_f1(total.is_anomaly.values.tolist(), total.alg_anomaly_score.values.tolist())\n",
    "                    \n",
    "                    if official_name not in f1_scores.keys():\n",
    "                        f1_scores[official_name] = f\n",
    "                        f1_scores_file[official_name] = result_file\n",
    "                        f1_scores_th[official_name] = th\n",
    "                    elif f > f1_scores[official_name]:\n",
    "                        f1_scores[official_name] = f\n",
    "                        f1_scores_file[official_name] = result_file\n",
    "                        f1_scores_th[official_name] = th\n",
    "                except:\n",
    "                    #traceback.print_exc()\n",
    "                    try:\n",
    "                        if official_name not in f1_scores.keys():\n",
    "                            f1_scores[official_name] = max(0, f)\n",
    "                        elif f > f1_scores[official_name]:\n",
    "                            f1_scores[official_name] = max(0, f)\n",
    "                    except:\n",
    "                        pass#print(alg_name, \",\", f)\n",
    "        return f1_scores\n",
    "    except:\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f342e0-959a-48d8-a208-3c7522486c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf6fbe7d-8aa4-4330-9927-a338eb2f3bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "import traceback\n",
    "import math\n",
    "from scipy.sparse import csc_matrix, hstack\n",
    "\n",
    "# code taken from https://github.com/HPI-Information-Systems/TimeEval-algorithms\n",
    "def post_grammarviz(algorithm_parameter):\n",
    "    if isinstance(algorithm_parameter, np.ndarray):\n",
    "        results = pd.DataFrame(algorithm_parameter, columns=[\"index\", \"score\", \"length\"])\n",
    "        results = results.set_index(\"index\")\n",
    "    else:\n",
    "        results = pd.read_csv(algorithm_parameter, header=None, index_col=0, names=[\"index\", \"score\", \"length\"])\n",
    "    anomalies = results[results[\"score\"] > .0]\n",
    "\n",
    "    # use scipy sparse matrix to save memory\n",
    "    matrix = csc_matrix((len(results), 1), dtype=np.float64)\n",
    "    counts = np.zeros(len(results))\n",
    "    for i, row in anomalies.iterrows():\n",
    "        idx = int(row.name)\n",
    "        length = int(row[\"length\"])\n",
    "        tmp = np.zeros(len(results))\n",
    "        tmp[idx:idx + length] = np.repeat([row[\"score\"]], repeats=length)\n",
    "        tmp = tmp.reshape(-1, 1)\n",
    "        matrix = hstack([matrix, tmp])\n",
    "        counts[idx:idx + length] += 1\n",
    "    sums = matrix.sum(axis=1)\n",
    "    counts = counts.reshape(-1, 1)\n",
    "    scores = np.zeros_like(sums)\n",
    "    np.divide(sums, counts, out=scores, where=counts != 0)\n",
    "    # returns the completely flattened array (from `[[1.2], [2.3]]` to `[1.2, 2.3]`)\n",
    "    return scores.A1  # type: ignore\n",
    "\n",
    "def calculate_roc(path_to_result, label_file, data_source, feasibility=None, validation=None):\n",
    "    try:\n",
    "        roc_scores = dict()\n",
    "        roc_scores_file = dict()\n",
    "        pr_scores = dict()\n",
    "        pr_scores_file = dict()\n",
    "        \n",
    "        i = 0\n",
    "        for result_file in os.listdir(path_to_result):\n",
    "            print(f\"{i}/{len(os.listdir(path_to_result))}: {result_file}                   \", end=\"\\r\")\n",
    "            i += 1\n",
    "            \n",
    "            if data_source in result_file and result_file.endswith(\".ts\"):\n",
    "                alg_name = result_file[:result_file.find(data_source)]\n",
    "                alg_name = '_'.join(alg_name.split('_')[1:])[:-1]\n",
    "                try:\n",
    "                    official_name = mapping_alg[mapping_alg.folder == alg_name].official_name.values[0]\n",
    "                    roc_auc, pr_auc = 0, 0\n",
    "                    \n",
    "                    if official_name == \"GrammarViz\":\n",
    "                        result_alg = post_grammarviz(path_to_result + result_file)\n",
    "                    else:\n",
    "                        result_alg = np.loadtxt(path_to_result + result_file)\n",
    "                        \n",
    "                    result_alg = pd.DataFrame(result_alg, columns=[\"alg_anomaly_score\"])\n",
    "                    result_alg[\"alg_anomaly_score\"] = result_alg[\"alg_anomaly_score\"].astype(float)\n",
    "                    result_alg = result_alg.fillna(0)\n",
    "                    result_alg.replace(np.inf, 1, inplace=True)\n",
    "                    result_alg.replace(-np.inf, 1, inplace=True)\n",
    "\n",
    "                    label = pd.read_csv(label_file)\n",
    "                    label = label[-len(result_alg):]\n",
    "                    label = label.reset_index(drop=True)\n",
    "\n",
    "                    if feasibility:\n",
    "                        label_feasibility = pd.read_csv(feasibility)\n",
    "\n",
    "                    total = pd.concat([result_alg, label], axis=1, join='inner')\n",
    "                    if feasibility:\n",
    "                        total = total[:len(total)-len(label_feasibility)]\n",
    "\n",
    "                    total = total.reset_index(drop=True)\n",
    "                    total = pd.concat([result_alg, label], axis=1, join='inner')\n",
    "                    observed_values = total.value.values.tolist()\n",
    "                    observed_values = [int(x) for x in observed_values]\n",
    "                    to_keep_comparision = remove_long_shutdown(observed_values, THRESHOLD_INDICATING_SHUTDOWN, MISSING_VALUE)\n",
    "                    total=total[total.index.isin(to_keep_comparision)]\n",
    "                    \n",
    "                    try:\n",
    "                        roc_auc = metrics.roc_auc_score(total.is_anomaly, total.alg_anomaly_score)\n",
    "                    except:\n",
    "                        roc_auc = 0\n",
    "\n",
    "                    try:\n",
    "                        y, x, _ = metrics.precision_recall_curve(total.is_anomaly, total.alg_anomaly_score)\n",
    "                        pr_auc = metrics.auc(x, y)\n",
    "                    except:\n",
    "                        pr_auc = 0\n",
    "                    \n",
    "                    if official_name not in roc_scores.keys():\n",
    "                        roc_scores[official_name] = roc_auc\n",
    "                        pr_scores[official_name] = pr_auc\n",
    "                        roc_scores_file[official_name] = pr_scores_file[official_name] = result_file\n",
    "                    else:\n",
    "                        if roc_auc > roc_scores[official_name]:\n",
    "                            roc_scores[official_name] = roc_auc\n",
    "                            roc_scores_file[official_name] = result_file\n",
    "                        if pr_auc > pr_scores[official_name]:\n",
    "                            pr_scores[official_name] = pr_auc\n",
    "                            pr_scores_file[official_name] = result_file\n",
    "                        \n",
    "                except:\n",
    "                    #traceback.print_exc()\n",
    "                    try:\n",
    "                        if official_name not in roc_scores.keys():\n",
    "                            roc_scores[official_name] = max(0, roc_auc)\n",
    "                            pr_scores[official_name] = max(0, pr_auc)\n",
    "                        else:\n",
    "                            if roc_auc > roc_scores[official_name]:\n",
    "                                roc_scores[official_name] = max(0, roc_auc)\n",
    "                            if pr_auc > pr_scores[official_name]:\n",
    "                                pr_scores[official_name] =max(0, pr_auc)\n",
    "                    except:\n",
    "                        pass\n",
    "        \n",
    "        return roc_scores, pr_scores\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4328498-a591-4659-9657-67691c7ef1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2554: adapad_valmod_Tide_Pressure.org_validation_00049.ts                                 \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ARIMA': 0.3555506173525368,\n",
       " 'Bagel': 0.8636314566394508,\n",
       " 'COUTA': 0.6829220702294757,\n",
       " 'Donut': 0.7356272955801119,\n",
       " 'DSPOT': 0.027888119725025987,\n",
       " 'DWT-MLEAD': 0.45454178148055363,\n",
       " 'EmsembleGI': 0.021629818330003964,\n",
       " 'FFT': 0.018208122562631122,\n",
       " 'RForest': 0.7654273739050993,\n",
       " 'XGBoosting': 0.7954496384600224,\n",
       " 'GrammarViz': 0.46153491126991325,\n",
       " 'HealthESN': 0.5822738343585041,\n",
       " 'HOT SAX': 0.02563642423154818,\n",
       " 'IE-CAE': 0.019342168216825394,\n",
       " 'Left STAMPi': 0.20167735334887696,\n",
       " 'MedianMethod': 0.7804830458350863,\n",
       " 'NormA-SJ': nan,\n",
       " 'NoveltySVR': 0.13869496443382615,\n",
       " 'NumetaHTM': 0.5097989235399653,\n",
       " 'OceanWNN': 0.7654273739050993,\n",
       " 'PCI': 0.5684160665257322,\n",
       " 'PS-SVM': 0.20353637722177848,\n",
       " 'PST': 0.26356114424751587,\n",
       " 'SAND': 0.1951171922636033,\n",
       " 'SARIMA': 0.5833290895370471,\n",
       " 'Series2Graph': 0.46153491126991325,\n",
       " 'SNPAD': 0.048579767134235674,\n",
       " 'SR-CNN': 0.07692233728521841,\n",
       " 'SR': 0.21373573811483443,\n",
       " 'SSA': 0.02417937634998633,\n",
       " 'STAMP': 0.2553145717836816,\n",
       " 'STOMP': 0.2553145717836816,\n",
       " 'Sub-Fast-MCD': 0.31759319571077516,\n",
       " 'Sub-IF': 0.15555154331336693,\n",
       " 'Sub-LOF': 0.07053362559404718,\n",
       " 'S-H-ESD': 0.7499953125292966,\n",
       " 'TARZAN': 0.5544504460797826,\n",
       " 'Triple ES': 0.3243199416224105,\n",
       " 'TSBitmap': 0.057237515487798304,\n",
       " 'VALMOD': 0.2553145717836816}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THRESHOLD_INDICATING_SHUTDOWN = 30\n",
    "MISSING_VALUE = -999\n",
    "OPERATION_VAL_RANGE = (713.682, 763.826)\n",
    "\n",
    "path_to_result = \"./Tide_pressure/\"\n",
    "label_file = \"../../../../01_data/01_label/Tide_Pressure.validation_stage.csv\"\n",
    "feasibility = None\n",
    "validation = \"../../../../01_data/01_label/Tide_Pressure.validation_stage.csv\"\n",
    "data_source = \"Tide_Pressure\"\n",
    "calculate_f1(path_to_result, label_file, data_source, feasibility,validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18b926f1-4a2e-46b0-abbc-4f901b849234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553/2554: adapad_valmod_Tide_Pressure.org_validation_00049.ts                                 \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'ARIMA': 0.8624109792284866,\n",
       "  'Bagel': 0.8787585034013605,\n",
       "  'COUTA': 0.8419841269841272,\n",
       "  'Donut': 0.8056552247297554,\n",
       "  'DSPOT': 0.6492284866468843,\n",
       "  'DWT-MLEAD': 0.7460608308605341,\n",
       "  'EmsembleGI': 0.5022793026706232,\n",
       "  'FFT': 0.5,\n",
       "  'RForest': 0.8133862433862433,\n",
       "  'XGBoosting': 0.8853269085411943,\n",
       "  'GrammarViz': 0.8528727744807121,\n",
       "  'HealthESN': 0.847089947089947,\n",
       "  'HOT SAX': 0.5061739614243324,\n",
       "  'IE-CAE': 0.34489040060468634,\n",
       "  'Left STAMPi': 0.6717611828560732,\n",
       "  'MedianMethod': 0.8008494065281899,\n",
       "  'NormA-SJ': 0.4171420623145401,\n",
       "  'NoveltySVR': 0.9224499258160237,\n",
       "  'NumetaHTM': 0.8336146142433234,\n",
       "  'OceanWNN': 0.7837490551776266,\n",
       "  'PCI': 0.8864057863501483,\n",
       "  'PS-SVM': 0.7958345697329376,\n",
       "  'PST': 0.6497793026706232,\n",
       "  'SAND': 0.8312314540059347,\n",
       "  'SARIMA': 0.8493175074183976,\n",
       "  'Series2Graph': 0.7809180267062314,\n",
       "  'SNPAD': 0.46567136498516326,\n",
       "  'SR-CNN': 0.5030876795162509,\n",
       "  'SR': 0.7593842729970327,\n",
       "  'SSA': 0.6233456973293768,\n",
       "  'STAMP': 0.602341972776431,\n",
       "  'STOMP': 0.6023438374044379,\n",
       "  'Sub-Fast-MCD': 0.9175459890005689,\n",
       "  'Sub-IF': 0.8259852635556395,\n",
       "  'Sub-LOF': 0.8040581900623465,\n",
       "  'S-H-ESD': 0.8099221068249258,\n",
       "  'TARZAN': 0.7768158543523611,\n",
       "  'Triple ES': 0.4797181008902077,\n",
       "  'TSBitmap': 0.5787685459940652,\n",
       "  'VALMOD': 0.6045552862203991},\n",
       " {'ARIMA': 0.32099955183546935,\n",
       "  'Bagel': 0.7650871540320471,\n",
       "  'COUTA': 0.5436324623282481,\n",
       "  'Donut': 0.6356551564178893,\n",
       "  'DSPOT': 0.42782482807463684,\n",
       "  'DWT-MLEAD': 0.32351562572392345,\n",
       "  'EmsembleGI': 0.008941303172006254,\n",
       "  'FFT': 0.5045938993017273,\n",
       "  'RForest': 0.6285514708954424,\n",
       "  'XGBoosting': 0.7095970429621873,\n",
       "  'GrammarViz': 0.350055729278452,\n",
       "  'HealthESN': 0.5172085078973485,\n",
       "  'HOT SAX': 0.016525830839502282,\n",
       "  'IE-CAE': 0.006346214657738094,\n",
       "  'Left STAMPi': 0.05148702521842262,\n",
       "  'MedianMethod': 0.6545628701352447,\n",
       "  'NormA-SJ': nan,\n",
       "  'NoveltySVR': 0.05174013824258558,\n",
       "  'NumetaHTM': 0.36181623951663855,\n",
       "  'OceanWNN': 0.6267766529385425,\n",
       "  'PCI': 0.5849188637395017,\n",
       "  'PS-SVM': 0.06075369032954426,\n",
       "  'PST': 0.12886447254949884,\n",
       "  'SAND': 0.057890223965261986,\n",
       "  'SARIMA': 0.4716333344081137,\n",
       "  'Series2Graph': 0.32055554222862054,\n",
       "  'SNPAD': 0.010735834205089032,\n",
       "  'SR-CNN': 0.05025459096267766,\n",
       "  'SR': 0.17869156183661283,\n",
       "  'SSA': 0.49621228767876496,\n",
       "  'STAMP': 0.10876330919813243,\n",
       "  'STOMP': 0.10879475506186431,\n",
       "  'Sub-Fast-MCD': 0.18486213733663928,\n",
       "  'Sub-IF': 0.049569015638779794,\n",
       "  'Sub-LOF': 0.0444086835333662,\n",
       "  'S-H-ESD': 0.7989994696134443,\n",
       "  'TARZAN': 0.31171493709040965,\n",
       "  'Triple ES': 0.24300643376743974,\n",
       "  'TSBitmap': 0.014762669751852217,\n",
       "  'VALMOD': 0.10882154771213523})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THRESHOLD_INDICATING_SHUTDOWN = 30\n",
    "MISSING_VALUE = -999\n",
    "OPERATION_VAL_RANGE = (713.682, 763.826)\n",
    "\n",
    "path_to_result = \"./Tide_pressure/\"\n",
    "label_file = \"../../../../01_data/01_label/Tide_Pressure.validation_stage.csv\"\n",
    "feasibility = None\n",
    "validation = \"../../../../01_data/01_label/Tide_Pressure.validation_stage.csv\"\n",
    "data_source = \"Tide_Pressure\"\n",
    "calculate_roc(path_to_result, label_file, data_source, feasibility,validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0d962df-209e-4813-be5b-1db7f7f6e8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1578/2167: adapad_ssa_Wave_Height_00026.ts                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_929/405303130.py\", line 90, in calculate_f1\n",
      "    f, th = get_best_f1(total.is_anomaly.values.tolist(), total.alg_anomaly_score.values.tolist())\n",
      "  File \"/tmp/ipykernel_929/405303130.py\", line 11, in get_best_f1\n",
      "    precision, recall, ths = metrics.precision_recall_curve(y_true=label, probas_pred=score)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py\", line 651, in precision_recall_curve\n",
      "    fps, tps, thresholds = _binary_clf_curve(y_true, probas_pred,\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py\", line 540, in _binary_clf_curve\n",
      "    raise ValueError(\"y_true takes value in {{{classes_repr}}} and \"\n",
      "ValueError: y_true takes value in {} and pos_label is not specified: either make y_true take value in {0, 1} or {-1, 1} or pass pos_label explicitly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1906/2167: adapad_subsequence_if_Wave_Height_00037.ts                         \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_929/405303130.py\", line 90, in calculate_f1\n",
      "    f, th = get_best_f1(total.is_anomaly.values.tolist(), total.alg_anomaly_score.values.tolist())\n",
      "  File \"/tmp/ipykernel_929/405303130.py\", line 11, in get_best_f1\n",
      "    precision, recall, ths = metrics.precision_recall_curve(y_true=label, probas_pred=score)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py\", line 651, in precision_recall_curve\n",
      "    fps, tps, thresholds = _binary_clf_curve(y_true, probas_pred,\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py\", line 540, in _binary_clf_curve\n",
      "    raise ValueError(\"y_true takes value in {{{classes_repr}}} and \"\n",
      "ValueError: y_true takes value in {} and pos_label is not specified: either make y_true take value in {0, 1} or {-1, 1} or pass pos_label explicitly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1955/2167: adapad_subsequence_lof_Wave_Height_00044.ts                   \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_929/405303130.py\", line 90, in calculate_f1\n",
      "    f, th = get_best_f1(total.is_anomaly.values.tolist(), total.alg_anomaly_score.values.tolist())\n",
      "  File \"/tmp/ipykernel_929/405303130.py\", line 11, in get_best_f1\n",
      "    precision, recall, ths = metrics.precision_recall_curve(y_true=label, probas_pred=score)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py\", line 651, in precision_recall_curve\n",
      "    fps, tps, thresholds = _binary_clf_curve(y_true, probas_pred,\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py\", line 540, in _binary_clf_curve\n",
      "    raise ValueError(\"y_true takes value in {{{classes_repr}}} and \"\n",
      "ValueError: y_true takes value in {} and pos_label is not specified: either make y_true take value in {0, 1} or {-1, 1} or pass pos_label explicitly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2166/2167: adapad_ts_bitmap_Wave_Height_00000.ts                         \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_929/405303130.py\", line 90, in calculate_f1\n",
      "    f, th = get_best_f1(total.is_anomaly.values.tolist(), total.alg_anomaly_score.values.tolist())\n",
      "  File \"/tmp/ipykernel_929/405303130.py\", line 11, in get_best_f1\n",
      "    precision, recall, ths = metrics.precision_recall_curve(y_true=label, probas_pred=score)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py\", line 651, in precision_recall_curve\n",
      "    fps, tps, thresholds = _binary_clf_curve(y_true, probas_pred,\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_ranking.py\", line 540, in _binary_clf_curve\n",
      "    raise ValueError(\"y_true takes value in {{{classes_repr}}} and \"\n",
      "ValueError: y_true takes value in {} and pos_label is not specified: either make y_true take value in {0, 1} or {-1, 1} or pass pos_label explicitly.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ARIMA': 0.32542415673758013,\n",
       " 'Bagel': 0.25636855338002246,\n",
       " 'Donut': 0.25636855338002246,\n",
       " 'DSPOT': 0.25378598362089644,\n",
       " 'DWT-MLEAD': 0.25378598362089644,\n",
       " 'EmsembleGI': 0.2539149509991404,\n",
       " 'FFT': 0.25378598362089644,\n",
       " 'RForest': 0.9909071512291495,\n",
       " 'XGBoosting': 0.9878410507301315,\n",
       " 'GrammarViz': 0.3006276147097895,\n",
       " 'HealthESN': 0.2743108937087809,\n",
       " 'HOT SAX': 0.25378598362089644,\n",
       " 'IE-CAE': 0.2808839786625813,\n",
       " 'Left STAMPi': 0.2830355975778745,\n",
       " 'MedianMethod': 0.6753361733612964,\n",
       " 'NormA-SJ': nan,\n",
       " 'NoveltySVR': 0.37864555414655077,\n",
       " 'NumetaHTM': 0.25378598362089644,\n",
       " 'OceanWNN': 0.9946294736767906,\n",
       " 'PCI': 0.8112510096762932,\n",
       " 'PS-SVM': 0.29818893986777756,\n",
       " 'PST': 0.4934423998845706,\n",
       " 'SAND': 0.26318966780190634,\n",
       " 'SARIMA': 0.7471897200630774,\n",
       " 'Series2Graph': 0.2949033607521636,\n",
       " 'SR-CNN': 0.2559991317824914,\n",
       " 'SR': 0.6985780283007601,\n",
       " 'SSA': 0.25537967037896203,\n",
       " 'STAMP': 0.2544105425895871,\n",
       " 'STOMP': 0.3228268900245595,\n",
       " 'Sub-Fast-MCD': 0.28458686284672724,\n",
       " 'Sub-IF': 0.2848589040031504,\n",
       " 'Sub-LOF': 0.2729502343514426,\n",
       " 'S-H-ESD': 0.25378598362089644,\n",
       " 'Triple ES': 0.6130791850891207,\n",
       " 'TSBitmap': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THRESHOLD_INDICATING_SHUTDOWN = 10\n",
    "MISSING_VALUE = -999\n",
    "OPERATION_VAL_RANGE = (0, 15.2)\n",
    "\n",
    "path_to_result = \"./Wave_height/\"\n",
    "label_file = \"../../../../01_data/01_label/Wave_height.csv\"\n",
    "feasibility = None\n",
    "validation = \"../../../../01_data/01_label/Wave_height.csv\"\n",
    "data_source = \"Wave_Height\"\n",
    "calculate_f1(path_to_result, label_file, data_source, feasibility,validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39ef8e01-35d5-4fc8-9551-972a0989c661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2166/2167: adapad_ts_bitmap_Wave_Height_00000.ts                              \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'ARIMA': 0.645037890641407,\n",
       "  'Bagel': 0.01555850773722926,\n",
       "  'Donut': 0.03958741583625515,\n",
       "  'DSPOT': 0.5037283694896617,\n",
       "  'DWT-MLEAD': 0.48058406871361015,\n",
       "  'EmsembleGI': 0.4835361975103841,\n",
       "  'FFT': 0.5,\n",
       "  'RForest': 0.9923987190542404,\n",
       "  'XGBoosting': 0.9863916162122999,\n",
       "  'GrammarViz': 0.6191372807812506,\n",
       "  'HealthESN': 0.5317771610601368,\n",
       "  'HOT SAX': 0.5014834620319767,\n",
       "  'IE-CAE': 0.5877291305697392,\n",
       "  'Left STAMPi': 0.6011516994294014,\n",
       "  'MedianMethod': 0.7676089599532606,\n",
       "  'NormA-SJ': 0,\n",
       "  'NoveltySVR': 0.635370072769254,\n",
       "  'NumetaHTM': 0.5091919475906985,\n",
       "  'OceanWNN': 0.9996380834497812,\n",
       "  'PCI': 0.9741901672394944,\n",
       "  'PS-SVM': 0.6326684796860225,\n",
       "  'PST': 0.6324931690137913,\n",
       "  'SAND': 0.4707744281780593,\n",
       "  'SARIMA': 0.9052232590681555,\n",
       "  'Series2Graph': 0.6146568879158236,\n",
       "  'SR-CNN': 0.37195747633629916,\n",
       "  'SR': 0.7663459133466555,\n",
       "  'SSA': 0.5104918499267994,\n",
       "  'STAMP': 0.5,\n",
       "  'STOMP': 0.636268932304365,\n",
       "  'Sub-Fast-MCD': 0.5796121057092339,\n",
       "  'Sub-IF': 0.60815176309983,\n",
       "  'Sub-LOF': 0.5038729353299936,\n",
       "  'S-H-ESD': 0.43412182142982825,\n",
       "  'Triple ES': 0.8652116347559367,\n",
       "  'TSBitmap': 0},\n",
       " {'ARIMA': 0.21843801644151267,\n",
       "  'Bagel': 0.07828969102348081,\n",
       "  'Donut': 0.07911512516467213,\n",
       "  'DSPOT': 0.22423854433606139,\n",
       "  'DWT-MLEAD': 0.14149974550685596,\n",
       "  'EmsembleGI': 0.13726144976266294,\n",
       "  'FFT': 0.5726682179561761,\n",
       "  'RForest': 0.9924796625016628,\n",
       "  'XGBoosting': 0.9872327563356161,\n",
       "  'GrammarViz': 0.23448305006203832,\n",
       "  'HealthESN': 0.15531666488173385,\n",
       "  'HOT SAX': 0.16947996459545528,\n",
       "  'IE-CAE': 0.19802254855298812,\n",
       "  'Left STAMPi': 0.20197951040528342,\n",
       "  'MedianMethod': 0.6685714251513661,\n",
       "  'NormA-SJ': nan,\n",
       "  'NoveltySVR': 0.30441174313292396,\n",
       "  'NumetaHTM': 0.24032859809735885,\n",
       "  'OceanWNN': 0.9985581483612153,\n",
       "  'PCI': 0.9087051437874436,\n",
       "  'PS-SVM': 0.23023080903031035,\n",
       "  'PST': 0.28235871149676806,\n",
       "  'SAND': 0.12980089715074847,\n",
       "  'SARIMA': 0.6193297909816265,\n",
       "  'Series2Graph': 0.20405727516804198,\n",
       "  'SR-CNN': 0.1107879950549705,\n",
       "  'SR': 0.6461785779777595,\n",
       "  'SSA': 0.5407557090336884,\n",
       "  'STAMP': 0.5728731161886242,\n",
       "  'STOMP': 0.25061726071250007,\n",
       "  'Sub-Fast-MCD': 0.20557615441843066,\n",
       "  'Sub-IF': 0.23213316149173757,\n",
       "  'Sub-LOF': 0.14714047505525796,\n",
       "  'S-H-ESD': 0.09400878602777409,\n",
       "  'Triple ES': 0.5898813328438204,\n",
       "  'TSBitmap': 0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THRESHOLD_INDICATING_SHUTDOWN = 10\n",
    "MISSING_VALUE = -999\n",
    "OPERATION_VAL_RANGE = (0, 15.2)\n",
    "\n",
    "path_to_result = \"./Wave_height/\"\n",
    "label_file = \"../../../../01_data/01_label/Wave_height.csv\"\n",
    "feasibility = None\n",
    "validation = \"../../../../01_data/01_label/Wave_height.csv\"\n",
    "data_source = \"Wave_Height\"\n",
    "calculate_roc(path_to_result, label_file, data_source, feasibility,validation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
